---
layout: post
title:  " Weight 초기화 잘해보자 "
categories: MachineLearning
author: goodGid
---
* content
{:toc}


<iframe width="560" height="315" src="https://www.youtube.com/embed/4rC0sWrp3Uw" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>


---


## Weight 초기화 잘해보자


![](/assets/img/machine_learning/ML_10_2_1.png)

 

문제 해결법으로 2가지 있다.

1. ReLU를 사용한다.

2. Weight의 초기값을 제대로 적용시키자.

<br>

<br>

그런데 ReLU를 사용할 때 

돌릴 때 마다 결과값이 다르다.


![](/assets/img/machine_learning/ML_10_2_2.png)

 

<br>

W를 초기화할 때 

[ -1 ~ 1 ] 랜덤값을 줬기 때문이다.

<br>

<br>


그러면 초기값을 0으로 주자 !


![](/assets/img/machine_learning/ML_10_2_3.png)

 

그러면 어떤 문제가 생길까?

여기서 x는 input값이기 때문에 0이 아닐수도 일수도 있다.

<br>

그런데 W를 0으로 초기화해줬기 때문에

그림의 좌상단 x쪽 부분의 미분 영역을 보면

`W`가 chain rule을 할 때 사용이 된다.

x라는 값과 상관없이 

기울기가 0이된다.

<br>


그렇게 되면 

그 뒤에 있는 모든 기울기가 `0`이 된다.

Q. 왜 뒤에 있는 모든 기울기가 0이 될까?
{: .notice}



다음과 같이 구성되어 있다 가정해보자.



![](/assets/img/machine_learning/ML_10_2_4.png)

 


그러면 

\\( \frac{df}{dy} \\) = \\( \frac{df}{dx} \\) * \\( \frac{dx}{dy} \\)

<br>

그런데 여기서 

\\( \frac{df}{dx} \\)의 값이 0 이라는 것을 알 수 있다.

그렇기 때문에 

뒤에 있는 모든 기울기는 자연스레 0이된다.




---

## How to solve?


![](/assets/img/machine_learning/ML_10_2_5.png)

 

* 우리는 초기값을 굉장히 잘 똑똑하게 초기화 해줘야한다.

* RBM 알고리즘을 사용하지 않아도 된다. 

<br>


![](/assets/img/machine_learning/ML_10_2_6.png)
![](/assets/img/machine_learning/ML_10_2_7.png)

 

* `Xavier initialization` : 2010년도 논문에서 발표

    * input Count와 output Count에 맞게 초기값을 셋팅해주면 된다.


![](/assets/img/machine_learning/ML_10_2_8.png)

 

<br>

* `He's initalization` : 2015년도 논문에서 발표

    * `Xavier initialization`를 수정/보완


![](/assets/img/machine_learning/ML_10_2_9.png)

 


---


## Activation functions and initailization on CIFAR-10


![](/assets/img/machine_learning/ML_10_2_10.png)

 


---

## Still in Research


![](/assets/img/machine_learning/ML_10_2_11.png)

 

이것 저것 실행시켜보고

가장 맞는 것을 사용하면 된다.


---

## Conclusion


![](/assets/img/machine_learning/ML_10_2_12.png)

 


2가지 문제가 해결되었기 때문에

딥러닝을 잘 학습시킬 수 있는 

모든 조건을 갖추었다.










