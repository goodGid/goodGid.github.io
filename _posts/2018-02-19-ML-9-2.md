---
layout: post
title:  " 딥넷트웍 학습 시키기 (backpropagation) "
categories: MachineLearning
author: goodGid
---
* content
{:toc}


<iframe width="560" height="315" src="https://www.youtube.com/embed/573EZkzfnZ0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>


---


## 딥넷트웍 학습 시키기 (Backpropagation)


![](/assets/img/machine_learning/ML_9_2_1.png)




위 사진이 무엇을 말하는지 알고 싶다면

가장 추천하고 싶은 방법은 동영상을 다시 보자 ...

교수님의 설명이 너무나 잘 되어 있다.

<br>

그래도 위 사진을 설명하자면

가장 오른쪽에 f로 부터 Back으로 타고타고 가는 것이다.

그렇게 되면 아무리 많은 관계가 있다하더라도 

결론적으로 해결할 수 가 있다는 원리이다.

<br>

\\( \frac{df}{dw} \\)는 w가 f에 어떤 영향을 미치는가를 뜻한다.

(내가 이해한 바로는) w가 f에 영향을 끼치기 위해선

중간에 g라는게 있으니 다음과 같은 식이 나온거라 생각한다. 

\\( \frac{df}{dw} \\) = \\( \frac{df}{dg} \\) * \\( \frac{dg}{dw} \\)

<br>

이러한 방식으로 

다음과 같은 복잡한 관계도 해결을 할 수가 있게 된다.


![](/assets/img/machine_learning/ML_9_2_2.png)




---



실제로 Tensorflow의 내부를 보면 

다음과 같은 구조로 이루어져 있다.


![](/assets/img/machine_learning/ML_9_2_3.png)
![](/assets/img/machine_learning/ML_9_2_4.png)




Why? 

Backpropagation 개념을 적용시키기 위해서 ! 

(= 각각을 미분하기 위해서)

